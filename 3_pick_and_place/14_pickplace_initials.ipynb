{"cells":[{"cellId":"1c589f77f48a4078a2d122107046cf0f","cell_type":"markdown","metadata":{"id":"EgiF12Hf1Dhs","colab_type":"text","cell_id":"1c589f77f48a4078a2d122107046cf0f","deepnote_cell_type":"markdown"},"source":"# Manipulating Assets\n\nIn this notebook you will program the robot to spell out your initials!. You will have to specify the start and goal poses of the gripper such that the letters in your initials are grasped and placed appropriately. You will also have to write a Jacobian-based velocity controller and connect it to the `HardwareStation` in your simulation diagram.\n\n\n**Learning Objectives:**\n1. Perform the necessary spatial algebra for designing grasp and placement poses\n2. Use Differential IK to write a gripper controller\n3. Understand the diagram structure for an actively controlled IIWA wrapped in a `HardwareStation`\n\n**What you'll build:** A simulation of the IIWA manipulating your initials such that they get placed in front of the robot. \n\n**Reference:** The structure is quite similar to the [Pick and Place Demo in Chapter 3](https://deepnote.com/workspace/Manipulation-ac8201a1-470a-4c77-afd0-2cc45bc229ff/project/65aad364-ef1c-45f5-a796-fac7c122e274/notebook/pick-d0b41e97e5124292af7ed01072ecece4) of Robotic Manipulation. <u> Take a moment to make sure that notebook makes sense to you.</u>\n\nLet's start by getting our imports out of the way and launching Meshcat. ","block_group":"d8dd4e5aad1345fa90a4160676a92058"},{"cellId":"8cad3c2c14954f8f9dfb06a547fb29b4","cell_type":"code","metadata":{"id":"eeMrMI0-1Dhu","colab":{},"colab_type":"code","cell_id":"8cad3c2c14954f8f9dfb06a547fb29b4","deepnote_cell_type":"code"},"source":"from pathlib import Path\n\nimport mpld3\nimport numpy as np\nfrom pydrake.all import (\n    AddFrameTriadIllustration,\n    BasicVector,\n    Context,\n    DiagramBuilder,\n    Integrator,\n    JacobianWrtVariable,\n    LeafSystem,\n    MultibodyPlant,\n    PiecewisePolynomial,\n    PiecewisePose,\n    RigidTransform,\n    RotationMatrix,\n    Simulator,\n    StartMeshcat,\n    Trajectory,\n    TrajectorySource,\n)\n\nfrom manipulation import running_as_notebook\nfrom manipulation.exercises.grader import Grader\nfrom manipulation.exercises.pick.test_pickplace_initials import TestPickPlacePoses\nfrom manipulation.letter_generation import create_sdf_asset_from_letter\nfrom manipulation.station import LoadScenario, MakeHardwareStation\n\nif running_as_notebook:\n    mpld3.enable_notebook()","block_group":"15f35d84f1b84e79aa812d128d1f1dba","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"1a9743e553194f56940e11fe09a1ead4","cell_type":"code","metadata":{"cell_id":"1a9743e553194f56940e11fe09a1ead4","deepnote_cell_type":"code"},"source":"# Start the visualizer.\nmeshcat = StartMeshcat()","block_group":"2a0b40feb39647e2b0835f46150ef0cc","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"c05aedab0ee04ce390483e0ff578c493","cell_type":"markdown","metadata":{"cell_id":"c05aedab0ee04ce390483e0ff578c493","deepnote_cell_type":"markdown"},"source":"# Design Grasp Pose\n\nThe grasp pose is commonly defined in the object frame so that the grasp pose ${^OX^G}$ is independent of the pose of the object. The grasp pose in the world frame can be computed by \n\n$${{^WX^G} = {}{^W}X^{O}} {^OX^G},$$\n\n\nwhere $W$ stands for the world frame and $G$ denotes the grasp frame, following the convention in the textbook.\n\n\nYou should notice from the visualization below that the gripper frame is different from the world frame. In particular, the +y axis of the gripper frame points vertically downward, and the +z axis of the gripper points backward. This is an important observation for this exercise.\n\nSimply commanding the gripper to the grasp pose does not ensure a collision-free path. To address this, we define a \"pre-pick\" poseâ€”a nearby position with enough clearance to let the robot move into the grasp pose without collisions.","block_group":"5a7d302410874023ad316fd17f613b2b"},{"cellId":"9bbdab653dca4129b4b017a2ac43dc35","cell_type":"markdown","metadata":{"cell_id":"9bbdab653dca4129b4b017a2ac43dc35","deepnote_cell_type":"markdown"},"source":"**Use the gripper and object's orientation from the image to design a grasp pose such that the gripper is 0.17 meters above the object frame.**\n\n**Given the object pose X_WO, we will need both X_OG, the grasp pose in the object frame, and X_WG, the grasp pose in the world frame.**\n\n**Remember that the X-axis is shown in red, Y-axis is in green, and Z-axis in blue.**","block_group":"916a65caa8a74ebab437475b101c33da"},{"cellId":"20f9ce59f5cf47e483e8fa3fc32c295f","cell_type":"markdown","metadata":{"cell_id":"20f9ce59f5cf47e483e8fa3fc32c295f","deepnote_cell_type":"markdown"},"source":"![ps2_fig.png](https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/grasp_letter.png)","block_group":"7d707acd8298417bbde7628cbad2e0c3"},{"cellId":"3dd6ee7ea6384e0eb7efd5e8b3cd0f0b","cell_type":"code","metadata":{"cell_id":"3dd6ee7ea6384e0eb7efd5e8b3cd0f0b","deepnote_cell_type":"code"},"source":"def design_grasp_pose(X_WO: RigidTransform) -> tuple[RigidTransform, RigidTransform]:\n    \"\"\"\n    fill in our code below\n    \"\"\"\n    X_OG = RigidTransform()\n    X_WG = RigidTransform()\n    return X_OG, X_WG","block_group":"512a576877404ad3aabcecf9850d07d5","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"960672e389d74f51ac577fe149d32ba3","cell_type":"markdown","metadata":{"cell_id":"960672e389d74f51ac577fe149d32ba3","deepnote_cell_type":"markdown"},"source":"# Design Goal Pose\nWe've figured out where the robot gripper needs to move given the initial pose of the objects. Now we need to decide where the gripper needs to go to place the object. \n\nYou'll notice in the figure that the first initial (\"S\") is facing the right direction but is offset translationally (it is behind the robot). You will design a placement pose for that first initial such that it is 0.4 meters left (-x in the world frame) of the second initial. \n\nThe second initial (\"C\") is located at the right pose, but is rotated so that it is facing perpendicular to the robot. We want it to have the same orientation as the first initial. In other words, you will design a placement pose for the second initial so that its y-axis point up in the world frame and its z-axis point along the world -y axis.\n\n**Write a function that takes the pose of your first initial and second initial and computes corrected poses for each. Then, given the grasp pose, find the correct gripper poses in the world frame to achieve these poses.**","block_group":"d2742618b45846db9910acb9d8c304ae"},{"cellId":"a51de4437ac24285b5db22dcd66e9d3e","cell_type":"markdown","metadata":{"cell_id":"a51de4437ac24285b5db22dcd66e9d3e","deepnote_cell_type":"markdown"},"source":"![ps2_2.png](https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/place_letter.png)","block_group":"6891fedfbc4c4a0195d9d7dfda76870b"},{"cellId":"fe45d728222c400492aed059134028a3","cell_type":"code","metadata":{"cell_id":"fe45d728222c400492aed059134028a3","deepnote_cell_type":"code"},"source":"def design_goal_poses(\n    X_WO1: RigidTransform, X_WO2: RigidTransform, X_OG: RigidTransform\n) -> tuple[RigidTransform, RigidTransform]:\n    \"\"\"\n    fill in our code below. We are designing poses for two objects, so we define\n    O1 as a frame centered on the first initial provided and O2 as a frame centered on the\n    second initial provided.\n    \"\"\"\n    X_WG1goal = RigidTransform()\n    X_WG2goal = RigidTransform()\n    return X_WG1goal, X_WG2goal","block_group":"36557688b5524ca19f09f58ce8bafb43","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"0b3324a93da3415682f4041b3a2402bd","cell_type":"markdown","metadata":{"cell_id":"0b3324a93da3415682f4041b3a2402bd","deepnote_cell_type":"markdown"},"source":"# Design Approach Pose\n\nFor both the pick and place poses, the gripper has to move close to the letters that are on the table. If it approaches those letters from the side, or if it moves one letter too close to the other, then the collision risks knocking over one of the two letters. To deal with this, we usually define \"pre-pick\" and \"pre-place\" poses for the gripper to go to. These poses have the property that the robot can achieve them without risking collision, and that the robot can move to the next pose in the trajectory without unwanted collisions. \n\n**Write a function that takes a gripper pose X_WG and returns an approach pose X_WGApproach. This frame will have a height of 0.1 when measured from frame G.**","block_group":"458b3ec50fd848668dcba2bd5b27a435"},{"cellId":"5da7271d219e47e09460788751ad26c4","cell_type":"code","metadata":{"cell_id":"5da7271d219e47e09460788751ad26c4","deepnote_cell_type":"code"},"source":"def approach_pose(X_WG: RigidTransform) -> RigidTransform:\n    \"\"\"\n    fill in our code below\n    \"\"\"\n    X_WGApproach = RigidTransform()\n    return X_WGApproach","block_group":"319708c48914487fa704514be47533fe","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"57fcf1c8c2b44cd09433cf15b1107b8b","cell_type":"markdown","metadata":{"cell_id":"57fcf1c8c2b44cd09433cf15b1107b8b","deepnote_cell_type":"markdown"},"source":"# From Keyframes to a Trajectory\n\nGreat! So to manipulate the two initials the robot is going to follow this trajectory\n- Start at its default configuration (gripper opened)\n- Move to the first prepick pose (gripper opened)\n- Move to the grasp pose (gripper opened)\n- Remain at the grasp pose (gripper closed)\n- move to the default configuration (gripper closed)\n- move to the first place pose (gripper closed)\n- remain at the first place pose (gripper opened)\n- return to the default configuration and repeat the process for the second initial\n\n\nWe've already solved for all of these poses! The next steps are to turn them into a valid trajectory we can command the robot to follow. \n\n**Your job is to implement the `MakeTrajectory` function.** It will take as input \n- a list of gripper poses of length L\n- an 1xL numpy array of gripper states (distance between the two fingers)\n- a list of timestamps of length L\n\nIt should return\n- the **velocities** corresponding to the Piecewise trajectory defined in terms of gripper poses (of type `Trajectory`)\n- a trajectory defining the state of the fingers.","block_group":"28f1c9fb12dc47c1b9147a044b7fc92a"},{"cellId":"d2350af0f911487eb7c4fef6bfe1d5dc","cell_type":"code","metadata":{"cell_id":"d2350af0f911487eb7c4fef6bfe1d5dc","deepnote_cell_type":"code"},"source":"def make_trajectory(\n    X_Gs: list[RigidTransform], finger_values: np.ndarray, sample_times: list[float]\n) -> tuple[Trajectory, PiecewisePolynomial]:\n    robot_velocity_trajectory = None\n    traj_wsg_command = None\n    # TODO: define a PiecewisePose out of the X_Gs\n\n    # TODO: set robot_velocity_trajectory to the derivative of the position trajectory you just defined\n\n    # TODO: set traj_wsg_command to a PiecewisePolynomial that commands the fingers\n\n    return robot_velocity_trajectory, traj_wsg_command","block_group":"4bb3428031254b16a189a057e9478000","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"59a5e3cb71db4b7e9734619bfdc7968b","cell_type":"markdown","metadata":{"cell_id":"59a5e3cb71db4b7e9734619bfdc7968b","deepnote_cell_type":"markdown"},"source":"# Initializing our System\n\nLet's spin up a system with all of our assets. First, we'll generate the asset files for our first and last initial as well as the table. Then, we define scenario directive in YAML format. Just like problem set 1! \n\nYou'll notice a new keyword in the call to `create_sdf_asset_from_letter` below. Now that we are manipulating these assets, not just spawning them into the scene, the choice of geometry we use to represent the letters impacts the physics of our simulation!. By setting `use_bbox_collision_geometry=True`, we are choosing to model the letters with their _Axis-Aligned Bounding Box_. This means that when MultibodyPlant is evaluating the dynamics of the scene, it will treat the letters as rectangular boxes. \n\n**Be sure to fill in your (2) initials!**","block_group":"198e04b4cd7d4e5a8d0dfbcd1036f6b5"},{"cellId":"9b861f5f1c0042de91674204d3dac88d","cell_type":"code","metadata":{"cell_id":"9b861f5f1c0042de91674204d3dac88d","deepnote_cell_type":"code"},"source":"initials = None","block_group":"12b4ce4b75ac40c39bef158556ee116d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"bfc79cd77b044b2bacd588064f7a1870","cell_type":"code","metadata":{"code_folding":[],"cell_id":"bfc79cd77b044b2bacd588064f7a1870","deepnote_cell_type":"code"},"source":"output_dir = Path(\"assets/\")\nfor letter in initials:\n    create_sdf_asset_from_letter(\n        text=letter,\n        font_name=\"DejaVu Sans\",\n        letter_height_meters=0.2,\n        extrusion_depth_meters=0.04,\n        output_dir=output_dir / f\"{letter}_model\",\n        use_bbox_collision_geometry=True,\n        mass=0.1,\n    )\nletter_sdfs = [\n    f\"{Path.cwd()}/assets/{letter}_model/{letter}.sdf\" for letter in initials\n]\n\ntable_sdf = \"\"\"<?xml version=\"1.0\"?>\n<sdf version=\"1.7\">\n  <model name=\"table\">\n    <pose>0 0 0 0 0 0</pose>\n    <link name=\"table_link\">\n      <inertial>\n        <mass>20</mass>\n        <inertia>\n          <ixx>1.0</ixx>\n          <ixy>0.0</ixy>\n          <ixz>0.0</ixz>\n          <iyy>1.0</iyy>\n          <iyz>0.0</iyz>\n          <izz>1.0</izz>\n        </inertia>\n      </inertial>\n      <collision name=\"box_collision\">\n        <geometry>\n          <box>\n            <size>2 2 0.1</size>\n          </box>\n        </geometry>\n      </collision>\n      <visual name=\"box_visual\">\n        <geometry>\n          <box>\n            <size>2 2 0.1</size>\n          </box>\n        </geometry>\n      </visual>\n    </link>\n  </model>\n</sdf>\n\"\"\"\n\nabs_table_sdf_path = \"assets/table.sdf\"\nwith open(abs_table_sdf_path, \"w\") as f:\n    f.write(table_sdf)\n\ntable_sdf = f\"{Path.cwd()}/assets/table.sdf\"\nscenario_yaml = f\"\"\"directives:\n- add_model:\n    name: iiwa\n    file: package://drake_models/iiwa_description/sdf/iiwa7_no_collision.sdf\n    default_joint_positions:\n        iiwa_joint_1: [-1.57]\n        iiwa_joint_2: [0.1]\n        iiwa_joint_3: [0]\n        iiwa_joint_4: [-1.2]\n        iiwa_joint_5: [0]\n        iiwa_joint_6: [ 1.6]\n        iiwa_joint_7: [0]\n- add_weld:\n    parent: world\n    child: iiwa::iiwa_link_0\n- add_model:\n    name: wsg\n    file: package://manipulation/hydro/schunk_wsg_50_with_tip.sdf\n- add_weld:\n    parent: iiwa::iiwa_link_7\n    child: wsg::body\n    X_PC:\n        translation: [0, 0, 0.09]\n        rotation: !Rpy {{ deg: [90, 0, 90]}}\n- add_model:\n    name: table\n    file: file://{table_sdf}\n- add_weld:\n    parent: world\n    child: table::table_link\n    X_PC:\n        translation: [0.0, 0.0, -0.05]\n        rotation: !Rpy {{ deg: [0, 0, -90] }}\n- add_model:\n    name: first_initial\n    file: file://{letter_sdfs[0]}\n    default_free_body_pose:\n        {initials[0]}_body_link:\n            translation: [0.5, -0.2, 0.01]\n            rotation: !Rpy {{ deg: [90, 0, 0] }}\n- add_model:\n    name: last_initial\n    file: file://{letter_sdfs[1]}\n    default_free_body_pose:\n        {initials[1]}_body_link:\n            translation: [-0.2, -0.5, 0.01]\n            rotation: !Rpy {{ deg: [90, 0, 90] }}\n\nmodel_drivers:\n    iiwa: !IiwaDriver\n      control_mode: position_only\n      hand_model_name: wsg\n    wsg: !SchunkWsgDriver {{}}\n\"\"\"\n\nscenario = LoadScenario(data=scenario_yaml)","block_group":"70ac20f240f741db8d232f4512e9bcb6","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"e3f8fa6cbd5e4f41bb9acc2b9260b922","cell_type":"markdown","metadata":{"cell_id":"e3f8fa6cbd5e4f41bb9acc2b9260b922","deepnote_cell_type":"markdown"},"source":"# Choice of Frames Impacts the Problem Statement!\n\nIn the above figures, notice that the coordinate frames are not actually placed at the center of the letters. Instead they are placed at their bottom-left corners. Defining grasp poses relative to these origins are tricky, because we want the robot gripper to be centered above the letter, but the letter-width varies with different initials. In the below function, let `S` describe the object frame as it is used in the SDF file corresponding to the geometry of the letter. Let `O` describe a frame placed at the center of mass of the object. The pick and place poses we defined above have frame `O` in mind, so let's make sure that that is the frame we are using. ","block_group":"364972c58bc5478b8ea5b7fbce5c0000"},{"cellId":"eb65010480ba485cb3bda4593b47e1dc","cell_type":"code","metadata":{"cell_id":"eb65010480ba485cb3bda4593b47e1dc","deepnote_cell_type":"code"},"source":"# Helper function to express mesh poses in terms of COM rather than geometric center\n\n\ndef get_initial_pose(\n    plant: MultibodyPlant, body_name: str, plant_context: Context\n) -> RigidTransform:\n    body = plant.GetBodyByName(body_name)\n    X_WS = plant.EvalBodyPoseInWorld(plant_context, body)\n    X_SO = RigidTransform(body.default_spatial_inertia().get_com())\n    return X_WS @ X_SO","block_group":"f78a0122a4b9463a8fbf661022077995","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"d69c1766529344beac5289afb9af0604","cell_type":"markdown","metadata":{"cell_id":"d69c1766529344beac5289afb9af0604","deepnote_cell_type":"markdown"},"source":"# A Jacobian Based Velocity Controller\nOk, we've specified the geometry of the scene, and our desired robot trajectory. Now we have to add the logic to relate our desired gripper velocities to robot joint velocities that we can command. \n\n**Your job is to implement the CalcOutput function. Recall that this takes the current context and sets a value for `output` based on this context.**","block_group":"d04f39b9915745449323a79df92196d6"},{"cellId":"1152ae93c635467586330321834a9874","cell_type":"code","metadata":{"cell_id":"1152ae93c635467586330321834a9874","deepnote_cell_type":"code"},"source":"class PseudoInverseController(LeafSystem):\n    def __init__(self, plant: MultibodyPlant):\n        LeafSystem.__init__(self)\n        self._plant = plant\n        self._plant_context = plant.CreateDefaultContext()\n        self._iiwa = plant.GetModelInstanceByName(\"iiwa\")\n        self._G = plant.GetBodyByName(\"body\").body_frame()\n        self._W = plant.world_frame()\n\n        self.V_G_port = self.DeclareVectorInputPort(\"V_WG\", 6)\n        self.q_port = self.DeclareVectorInputPort(\"iiwa.position\", 7)\n        self.DeclareVectorOutputPort(\"iiwa.velocity\", 7, self.CalcOutput)\n        self.iiwa_start = plant.GetJointByName(\"iiwa_joint_1\").velocity_start()\n        self.iiwa_end = plant.GetJointByName(\"iiwa_joint_7\").velocity_start()\n\n    def CalcOutput(self, context: Context, output: BasicVector):\n        \"\"\"\n        fill in our code below.\n        \"\"\"\n        # evaluate the V_G_port and q_port on the current context to get those values.\n\n        # update the positions of the internal _plant_context according to `q`.\n        # HINT: you can write to a plant context by calling `self._plant.SetPositions`\n\n        # Compute the gripper jacobian\n        # HINT: the jacobian is 6 x N, with N being the number of DOFs.\n        # We only want the 6 x 7 submatrix corresponding to the IIWA\n\n        # compute `v` by mapping the gripper velocity (from the V_G_port) to the joint space\n        v = None\n        output.SetFromVector(v)","block_group":"0058cc372cff49f6b22f7dc096d3186a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"ad60bfe2c2a94068b1dbf5f846cf047a","cell_type":"markdown","metadata":{"cell_id":"ad60bfe2c2a94068b1dbf5f846cf047a","deepnote_cell_type":"markdown"},"source":"# Putting everything together\n\nWe're almost done! Let's use the scenario we defined to initialize a diagram, and specify the keyframes as well!\n\nWe've added all the systems needed for the diagram to the builder. **Your job will be to connect all the necessary input and output ports for simulation.**","block_group":"e44cc40ae78143da8a375bf808e27875"},{"cellId":"28b969e85ef548ef8aa3df18090b7535","cell_type":"code","metadata":{"cell_id":"28b969e85ef548ef8aa3df18090b7535","deepnote_cell_type":"code"},"source":"# Define the builder we will use to specify the full diagram.\n# Add the hardware station to the diagram\nbuilder = DiagramBuilder()\nstation = MakeHardwareStation(scenario, meshcat=meshcat)\nbuilder.AddSystem(station)\nplant = station.GetSubsystemByName(\"plant\")\n\n# get initial poses of gripper and objects\ntemp_context = station.CreateDefaultContext()\ntemp_plant_context = plant.GetMyContextFromRoot(temp_context)\nX_WGinitial = plant.EvalBodyPoseInWorld(temp_plant_context, plant.GetBodyByName(\"body\"))\nX_WO1initial = get_initial_pose(plant, f\"{initials[0]}_body_link\", temp_plant_context)\nX_WO2initial = get_initial_pose(plant, f\"{initials[1]}_body_link\", temp_plant_context)\n\n# Build trajectory keyframes\nX_OG, X_WG2pick = design_grasp_pose(X_WO2initial)\n_, X_WG1pick = design_grasp_pose(X_WO1initial)\nX_WG1prepick, X_WG2prepick = approach_pose(X_WG1pick), approach_pose(X_WG2pick)\nX_WG1goal, X_WG2goal = design_goal_poses(X_WO1initial, X_WO2initial, X_OG)\nX_WG1pregoal, X_WG2pregoal = approach_pose(X_WG1goal), approach_pose(X_WG2goal)\n\n\n# constants for finger distances when the gripper is opened or closed\nopened = 0.107\nclosed = 0.0\n\n# list of keyframes, formatted as (gripper poses, finger states)\n# for each object the robot starts in its default pose with its gripper open\n# then it goes to the prepick pose, the pick pose, closes the gripper, and then goes\n# to the place pose\nkeyframes = [\n    (X_WGinitial, opened),\n    (X_WG2prepick, opened),\n    (X_WG2pick, opened),\n    (X_WG2pick, closed),\n    (X_WGinitial, closed),\n    (X_WG2pregoal, closed),\n    (X_WG2goal, closed),\n    (X_WG2goal, closed),\n    (X_WG2goal, opened),\n    (X_WGinitial, opened),\n    (X_WG1prepick, opened),\n    (X_WG1pick, opened),\n    (X_WG1pick, closed),\n    (X_WGinitial, closed),\n    (X_WG1pregoal, closed),\n    (X_WG1goal, closed),\n    (X_WG1goal, opened),\n    (X_WGinitial, opened),\n]\n\n# unpack the keyframes and use them to build `Trajectory` objects\n# note: we specify each keyframe as occuring 2 seconds after the last.\ngripper_poses = [keyframe[0] for keyframe in keyframes]\nfinger_states = np.asarray([keyframe[1] for keyframe in keyframes]).reshape(1, -1)\nsample_times = [2 * i for i in range(len(gripper_poses))]\ntraj_V_G, traj_wsg_command = make_trajectory(gripper_poses, finger_states, sample_times)\n\n# V_G_source defines a trajectory over gripper velocities. Add it to the system.\nV_G_source = builder.AddSystem(TrajectorySource(traj_V_G))\n# Add the DiffIK controller we just defined to the system\ncontroller = builder.AddSystem(PseudoInverseController(plant))\n# The HardwareStation expects robot commands in terms of joint angles.\n# We define the `integrator` system to map from joint_velocities to joint_angles.\nintegrator = builder.AddSystem(Integrator(7))\n# wsg_source defines a trajectory of finger positions. Add it to the system.\nwsg_source = builder.AddSystem(TrajectorySource(traj_wsg_command))\n\n# TODO: connect the joint velocity source to the pseudoinverse controller\n\n# TODO: connect the controller to integrator to get joint angle commands\n\n# TODO: connect the joint angles computed by the integrateor to the iiwa.position port on the manipulation station\n\n# TODO: connect the \"iiwa.position_measured\" port on the station back to the relevant input port on the controller\n\n# TODO: connect the wsg_source to the \"wsg.position\" input port of the station\n\n# visualize axes (useful for debugging)\nscenegraph = station.GetSubsystemByName(\"scene_graph\")\nAddFrameTriadIllustration(\n    scene_graph=scenegraph,\n    body=plant.GetBodyByName(f\"{initials[0]}_body_link\"),\n    length=0.1,\n)\nAddFrameTriadIllustration(\n    scene_graph=scenegraph,\n    body=plant.GetBodyByName(f\"{initials[1]}_body_link\"),\n    length=0.1,\n)\nAddFrameTriadIllustration(\n    scene_graph=scenegraph, body=plant.GetBodyByName(\"body\"), length=0.1\n)\n\ndiagram = builder.Build()","block_group":"b682bbf5adcb46d3be2d29a9c9b12287","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"c35a3ebbaa064e118f3ec490b89f587e","cell_type":"code","metadata":{"cell_id":"c35a3ebbaa064e118f3ec490b89f587e","deepnote_cell_type":"code"},"source":"# Define the simulator.\nsimulator = Simulator(diagram)\ncontext = simulator.get_mutable_context()\nstation_context = station.GetMyContextFromRoot(context)\nintegrator.set_integral_value(\n    integrator.GetMyContextFromRoot(context),\n    plant.GetPositions(\n        plant.GetMyContextFromRoot(context),\n        plant.GetModelInstanceByName(\"iiwa\"),\n    ),\n)\ndiagram.ForcedPublish(context)\nprint(f\"sanity check, simulation will run for {traj_V_G.end_time()} seconds\")\n\n# run simulation!\nmeshcat.StartRecording()\nif running_as_notebook:\n    simulator.set_target_realtime_rate(1.0)\nsimulator.AdvanceTo(traj_V_G.end_time())\nmeshcat.StopRecording()\nmeshcat.PublishRecording()","block_group":"97ab97d58d88450ea19bd86a36cf4624","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"d78c000439af4c27aac83a29668d8b7f","cell_type":"code","metadata":{"cell_id":"d78c000439af4c27aac83a29668d8b7f","deepnote_cell_type":"code"},"source":"# Use this to test your implementation if you want!\nGrader.grade_output([TestPickPlacePoses], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")","block_group":"69e512c9d5eb4b669adab589eb9ba11b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"06de59545606411792560135a435a99c","cell_type":"markdown","metadata":{"cell_id":"06de59545606411792560135a435a99c","deepnote_cell_type":"markdown"},"source":"# Improving on computed grasp poses\n\nCongratulations! The IIWA should now be manipulating your initials so that they sit next to each other. Now, go back to meshcat and in the top-right select \"Open Controls\", then \"scene\", then \"drake\", then \"proximity\". You will notice that the collision geometries are currently represented as bounding boxes around the letters. \n\nIf the robot fails to grasp a letter, or if the letter seems to be slipping inside the robot's fingers, experiment with different grasp poses. Different letters may call for higher or lower grasps. \n\n\n**Once you have everything working, take a video and upload it to gradescope!**","block_group":"c068d24ecb2e4ab68d4cbd6bd0a1ad62"}],
        "metadata": {"deepnote_notebook_id":"fa3aa790582c4980ae1feb5cd3f37275"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }